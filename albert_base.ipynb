{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsi9t_yULuSh"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bi2MmXBL2H6"
      },
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZJdD5mgU3CB"
      },
      "source": [
        "! git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV7kL7UGL4HS",
        "outputId": "5cbe04ed-a9b0-4c27-8887-297b1684a9bc"
      },
      "source": [
        "!export SQUAD_DIR=/content/dataset \\\n",
        "&& python /content/transformers/examples/question-answering/run_squad.py \\\n",
        "  --model_type albert \\\n",
        "  --model_name_or_path albert-base-v2 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --train_file $SQUAD_DIR/train-v2.0.json \\\n",
        "  --predict_file $SQUAD_DIR/dev-v2.0.json \\\n",
        "  --per_gpu_train_batch_size 12 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 2.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir /content/model_output \\\n",
        "  --save_steps 1000 \\\n",
        "  --threads 4 \\\n",
        "  --version_2_with_negative \\\n",
        "  --overwrite_output_dir\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration: 100% 10988/11017 [52:07<00:08,  3.39it/s]\u001b[A\n",
            "Iteration: 100% 10989/11017 [52:08<00:08,  3.43it/s]\u001b[A\n",
            "Iteration: 100% 10990/11017 [52:08<00:07,  3.46it/s]\u001b[A\n",
            "Iteration: 100% 10991/11017 [52:08<00:07,  3.48it/s]\u001b[A\n",
            "Iteration: 100% 10992/11017 [52:09<00:07,  3.49it/s]\u001b[A\n",
            "Iteration: 100% 10993/11017 [52:09<00:06,  3.50it/s]\u001b[A\n",
            "Iteration: 100% 10994/11017 [52:09<00:06,  3.50it/s]\u001b[A\n",
            "Iteration: 100% 10995/11017 [52:09<00:06,  3.50it/s]\u001b[A\n",
            "Iteration: 100% 10996/11017 [52:10<00:05,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 10997/11017 [52:10<00:05,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 10998/11017 [52:10<00:05,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 10999/11017 [52:11<00:05,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11000/11017 [52:11<00:04,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11001/11017 [52:11<00:04,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11002/11017 [52:11<00:04,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11003/11017 [52:12<00:03,  3.53it/s]\u001b[A\n",
            "Iteration: 100% 11004/11017 [52:12<00:03,  3.53it/s]\u001b[A\n",
            "Iteration: 100% 11005/11017 [52:12<00:03,  3.53it/s]\u001b[A\n",
            "Iteration: 100% 11006/11017 [52:13<00:03,  3.53it/s]\u001b[A\n",
            "Iteration: 100% 11007/11017 [52:13<00:02,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11008/11017 [52:13<00:02,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11009/11017 [52:13<00:02,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 11010/11017 [52:14<00:01,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11011/11017 [52:14<00:01,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11012/11017 [52:14<00:01,  3.53it/s]\u001b[A\n",
            "Iteration: 100% 11013/11017 [52:15<00:01,  3.52it/s]\u001b[A\n",
            "Iteration: 100% 11014/11017 [52:15<00:00,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 11015/11017 [52:15<00:00,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 11016/11017 [52:15<00:00,  3.51it/s]\u001b[A\n",
            "Iteration: 100% 11017/11017 [52:16<00:00,  3.51it/s]\n",
            "Epoch: 100% 2/2 [1:44:35<00:00, 3137.67s/it]\n",
            "11/28/2020 01:53:04 - INFO - __main__ -    global_step = 22035, average loss = 0.8249907404809872\n",
            "11/28/2020 01:53:04 - INFO - __main__ -   Saving model checkpoint to /content/model_output\n",
            "[INFO|configuration_utils.py:282] 2020-11-28 01:53:04,606 >> Configuration saved in /content/model_output/config.json\n",
            "[INFO|modeling_utils.py:740] 2020-11-28 01:53:04,704 >> Model weights saved in /content/model_output/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:411] 2020-11-28 01:53:04,706 >> loading configuration file /content/model_output/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-28 01:53:04,706 >> Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"albert-base-v2\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:938] 2020-11-28 01:53:04,706 >> loading weights file /content/model_output/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1056] 2020-11-28 01:53:05,050 >> All model checkpoint weights were used when initializing AlbertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:1065] 2020-11-28 01:53:05,051 >> All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at /content/model_output.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "[INFO|configuration_utils.py:411] 2020-11-28 01:53:05,051 >> loading configuration file /content/model_output/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-28 01:53:05,052 >> Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"albert-base-v2\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1577] 2020-11-28 01:53:05,052 >> Model name '/content/model_output' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '/content/model_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-28 01:53:05,052 >> Didn't find file /content/model_output/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-28 01:53:05,052 >> Didn't find file /content/model_output/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-28 01:53:05,052 >> loading file /content/model_output/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-28 01:53:05,052 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-28 01:53:05,052 >> loading file /content/model_output/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-28 01:53:05,052 >> loading file /content/model_output/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-28 01:53:05,052 >> loading file None\n",
            "11/28/2020 01:53:05 - INFO - __main__ -   Loading checkpoints saved during training for evaluation\n",
            "11/28/2020 01:53:05 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/model_output']\n",
            "[INFO|configuration_utils.py:411] 2020-11-28 01:53:05,127 >> loading configuration file /content/model_output/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-28 01:53:05,128 >> Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"albert-base-v2\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:938] 2020-11-28 01:53:05,128 >> loading weights file /content/model_output/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1056] 2020-11-28 01:53:05,448 >> All model checkpoint weights were used when initializing AlbertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:1065] 2020-11-28 01:53:05,448 >> All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at /content/model_output.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "11/28/2020 01:53:05 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 35/35 [00:03<00:00,  9.30it/s]\n",
            "convert squad examples to features:   0% 0/11873 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n",
            "convert squad examples to features: 100% 11873/11873 [00:47<00:00, 250.09it/s]\n",
            "add example index and unique id: 100% 11873/11873 [00:00<00:00, 780254.63it/s]\n",
            "11/28/2020 01:53:57 - INFO - __main__ -   Saving features into cached file ./cached_dev_albert-base-v2_384\n",
            "11/28/2020 01:54:10 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "11/28/2020 01:54:10 - INFO - __main__ -     Num examples = 12272\n",
            "11/28/2020 01:54:10 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 1534/1534 [01:43<00:00, 14.86it/s]\n",
            "11/28/2020 01:55:53 - INFO - __main__ -     Evaluation done in total 103.218413 secs (0.008411 sec per example)\n",
            "[INFO|squad_metrics.py:389] 2020-11-28 01:55:53,862 >> Writing predictions to: /content/model_output/predictions_.json\n",
            "[INFO|squad_metrics.py:391] 2020-11-28 01:55:53,862 >> Writing nbest to: /content/model_output/nbest_predictions_.json\n",
            "[INFO|squad_metrics.py:393] 2020-11-28 01:55:53,862 >> Writing null_log_odds to: /content/model_output/null_odds_.json\n",
            "11/28/2020 01:56:40 - INFO - __main__ -   Results: {'exact': 78.6321906847469, 'f1': 81.11892727885796, 'total': 11873, 'HasAns_exact': 75.13495276653171, 'HasAns_f1': 81.47750735186924, 'HasAns_total': 5928, 'NoAns_exact': 80.11942809083263, 'NoAns_f1': 80.11942809083263, 'NoAns_total': 5945, 'best_exact': 78.6321906847469, 'best_exact_thresh': 0.0, 'best_f1': 81.11892727885792, 'best_f1_thresh': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Md_MR_Mo_t"
      },
      "source": [
        "Results: {'exact': 78.6321906847469, 'f1': 81.11892727885796, 'total': 11873,\n",
        "          'HasAns_exact': 75.13495276653171, 'HasAns_f1': 81.47750735186924, 'HasAns_total': 5928,\n",
        "          'NoAns_exact': 80.11942809083263, 'NoAns_f1': 80.11942809083263, 'NoAns_total': 5945,\n",
        "          'best_exact': 78.6321906847469, 'best_exact_thresh': 0.0, 'best_f1': 81.11892727885792, 'best_f1_thresh': 0.0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IARBOBDlMrTN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}