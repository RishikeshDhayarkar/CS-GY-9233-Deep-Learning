{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC07Ql5QRYte"
      },
      "source": [
        "In this notebook we perform ensembling on the prediction obtained from BERT, ALBERT, RoBERTa, DistilBERT. \r\n",
        "\r\n",
        "After training, every model generates a file called. 'predictions'. Contents of this file include a predicted answer for every question. \r\n",
        "We predictions from all of the above models to create an ensemble based on majority voting.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlPz3MFBpiuw",
        "outputId": "db0391dc-fc76-4fff-b975-9f3014dce471"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH50xqhLpcW-"
      },
      "source": [
        "import json \n",
        "  \n",
        "f = open('/content/drive/MyDrive/all_predictions/predictions_albert.json',) \n",
        "data_albert = json.load(f) \n",
        "f.close() \n",
        "\n",
        "g = open('/content/drive/MyDrive/all_predictions/predictions_bert.json',) \n",
        "data_bert = json.load(g) \n",
        "g.close() \n",
        "\n",
        "h = open('/content/drive/MyDrive/all_predictions/predictions_distilbert.json',) \n",
        "data_distilbert = json.load(h) \n",
        "h.close() \n",
        "\n",
        "i = open('/content/drive/MyDrive/all_predictions/predictions_roberta.json',) \n",
        "data_roberta = json.load(i) \n",
        "i.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_W7aXjt8n5q"
      },
      "source": [
        "ids = []\r\n",
        "for key in data_albert:\r\n",
        "    ids.append(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkR1Y831rbq1"
      },
      "source": [
        "answers_albert = []\n",
        "answers_bert = []\n",
        "answers_distilbert = []\n",
        "answers_roberta = []\n",
        "\n",
        "for id in ids:\n",
        "    answers_albert.append(data_albert[id])\n",
        "\n",
        "for id in ids:\n",
        "    answers_bert.append(data_bert[id])\n",
        "\n",
        "for id in ids:\n",
        "    answers_distilbert.append(data_distilbert[id])\n",
        "\n",
        "for id in ids:\n",
        "    answers_roberta.append(data_roberta[id])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxgbeDgwsY5_"
      },
      "source": [
        "all_preds = [] \n",
        "for i in range(len(ids)):\n",
        "    all_preds.append([ids[i], answers_albert[i], answers_bert[i], answers_distilbert[i], answers_roberta[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E409UyMbjnFo",
        "outputId": "c40f0745-f47b-46a5-e04d-8e3f4c9a0409"
      },
      "source": [
        "all_preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['56ddde6b9a695914005b9628', 'France', 'France', 'France', 'France.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9NrZU1QLvG4O",
        "outputId": "034eaf11-f184-4f6f-a016-171b3616754a"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(all_preds, columns = ['ids', 'albert answers', 'bert answers', 'distilbert answers', 'roberta answers'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>albert answers</th>\n",
              "      <th>bert answers</th>\n",
              "      <th>distilbert answers</th>\n",
              "      <th>roberta answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56ddde6b9a695914005b9628</td>\n",
              "      <td>France</td>\n",
              "      <td>France</td>\n",
              "      <td>France</td>\n",
              "      <td>France.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56ddde6b9a695914005b9629</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56ddde6b9a695914005b962a</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56ddde6b9a695914005b962b</td>\n",
              "      <td></td>\n",
              "      <td>Rollo</td>\n",
              "      <td>Rollo</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56ddde6b9a695914005b962c</td>\n",
              "      <td>10th</td>\n",
              "      <td>10th</td>\n",
              "      <td>10th</td>\n",
              "      <td>10th</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        ids  ...              roberta answers\n",
              "0  56ddde6b9a695914005b9628  ...                      France.\n",
              "1  56ddde6b9a695914005b9629  ...      10th and 11th centuries\n",
              "2  56ddde6b9a695914005b962a  ...  Denmark, Iceland and Norway\n",
              "3  56ddde6b9a695914005b962b  ...                             \n",
              "4  56ddde6b9a695914005b962c  ...                         10th\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3nJ8lH-jIof",
        "outputId": "64557537-373c-491a-81d7-0b1505e725b2"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11873, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TRnMfkIwOmV"
      },
      "source": [
        "from collections import Counter\n",
        "import operator\n",
        "\n",
        "fin_preds = []\n",
        "for i in range(len(ids)):\n",
        "    d = Counter(all_preds[i][1:])\n",
        "    fin_preds.append([ids[i], max(d.items(), key=operator.itemgetter(1))[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "2WAJhsnMwOjr",
        "outputId": "d56a09fc-ffab-4a7c-e73e-c5da35465ccb"
      },
      "source": [
        "df_fin = pd.DataFrame(fin_preds, columns = ['ids', 'ensembled answers'])\n",
        "df_fin.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>ensembled answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56ddde6b9a695914005b9628</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56ddde6b9a695914005b9629</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56ddde6b9a695914005b962a</td>\n",
              "      <td>Denmark, Iceland and Norway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56ddde6b9a695914005b962b</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56ddde6b9a695914005b962c</td>\n",
              "      <td>10th</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        ids            ensembled answers\n",
              "0  56ddde6b9a695914005b9628                       France\n",
              "1  56ddde6b9a695914005b9629      10th and 11th centuries\n",
              "2  56ddde6b9a695914005b962a  Denmark, Iceland and Norway\n",
              "3  56ddde6b9a695914005b962b                             \n",
              "4  56ddde6b9a695914005b962c                         10th"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEZcUE49-mFw"
      },
      "source": [
        "Replace no answers with roberta answers\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfn0m67d-h61"
      },
      "source": [
        "fin_preds_dict = {}\r\n",
        "\r\n",
        "for l in fin_preds:\r\n",
        "    fin_preds_dict[l[0]] = l[1]\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qd8-2Ku-hy8"
      },
      "source": [
        "for i in data_roberta:\r\n",
        "    if data_roberta[i]=='':\r\n",
        "        fin_preds_dict[i] = data_roberta[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heBfewksHX26"
      },
      "source": [
        "processed_fin_preds = []\r\n",
        "\r\n",
        "for key in fin_preds_dict.keys():\r\n",
        "    processed_fin_preds.append([key, fin_preds_dict[key]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flPa-D9Q-hvY",
        "outputId": "51d73cef-8c2a-4afa-fe7e-d857bebd868c"
      },
      "source": [
        "processed_fin_preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['56ddde6b9a695914005b9628', 'France']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDzySJKUVnbf",
        "outputId": "0a23e5fa-6362-4746-deef-bfd5e91b5b07"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 25.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 16.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=948a7a6d01d65c4aaab8ba8e25d5d6b24c22bd47ca923360889f48ac599b1b71\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeldQxaPdDWd"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/all_predictions/examples.pickle', 'rb') as handle:\n",
        "    examples = pickle.load(handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/all_predictions/predictions.pickle', 'rb') as handle:\n",
        "    predictions = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIXPKi9pWIDs"
      },
      "source": [
        "import collections\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import string\n",
        "\n",
        "from transformers import BasicTokenizer\n",
        "\n",
        "# from ...utils import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od0tF4RBWQDS"
      },
      "source": [
        "def compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TFdXGnxWS8s"
      },
      "source": [
        "def get_raw_scores(examples, preds):\n",
        "    \"\"\"\n",
        "    Computes the exact and f1 scores from the examples and the model predictions\n",
        "    \"\"\"\n",
        "    exact_scores = {}\n",
        "    f1_scores = {}\n",
        "\n",
        "    for example in examples:\n",
        "        qas_id = example.qas_id\n",
        "        gold_answers = [answer[\"text\"] for answer in example.answers if normalize_answer(answer[\"text\"])]\n",
        "\n",
        "        if not gold_answers:\n",
        "            # For unanswerable questions, only correct answer is empty string\n",
        "            gold_answers = [\"\"]\n",
        "\n",
        "        if qas_id not in preds:\n",
        "            print(\"Missing prediction for %s\" % qas_id)\n",
        "            continue\n",
        "\n",
        "        prediction = preds[qas_id]\n",
        "        exact_scores[qas_id] = max(compute_exact(a, prediction) for a in gold_answers)\n",
        "        f1_scores[qas_id] = max(compute_f1(a, prediction) for a in gold_answers)\n",
        "\n",
        "    return exact_scores, f1_scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUYS7yfgWU7A"
      },
      "source": [
        "def apply_no_ans_threshold(scores, na_probs, qid_to_has_ans, na_prob_thresh):\n",
        "    new_scores = {}\n",
        "    for qid, s in scores.items():\n",
        "        pred_na = na_probs[qid] > na_prob_thresh\n",
        "        if pred_na:\n",
        "            new_scores[qid] = float(not qid_to_has_ans[qid])\n",
        "        else:\n",
        "            new_scores[qid] = s\n",
        "    return new_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeZduLfMWYNO"
      },
      "source": [
        "def make_eval_dict(exact_scores, f1_scores, qid_list=None):\n",
        "    if not qid_list:\n",
        "        total = len(exact_scores)\n",
        "        return collections.OrderedDict(\n",
        "            [\n",
        "                (\"exact\", 100.0 * sum(exact_scores.values()) / total),\n",
        "                (\"f1\", 100.0 * sum(f1_scores.values()) / total),\n",
        "                (\"total\", total),\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        total = len(qid_list)\n",
        "        return collections.OrderedDict(\n",
        "            [\n",
        "                (\"exact\", 100.0 * sum(exact_scores[k] for k in qid_list) / total),\n",
        "                (\"f1\", 100.0 * sum(f1_scores[k] for k in qid_list) / total),\n",
        "                (\"total\", total),\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_-LEUGQWYFS"
      },
      "source": [
        "def merge_eval(main_eval, new_eval, prefix):\n",
        "    for k in new_eval:\n",
        "        main_eval[\"%s_%s\" % (prefix, k)] = new_eval[k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb-eNv4eWlGm"
      },
      "source": [
        "def find_best_thresh_v2(preds, scores, na_probs, qid_to_has_ans):\n",
        "    num_no_ans = sum(1 for k in qid_to_has_ans if not qid_to_has_ans[k])\n",
        "    cur_score = num_no_ans\n",
        "    best_score = cur_score\n",
        "    best_thresh = 0.0\n",
        "    qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n",
        "    for i, qid in enumerate(qid_list):\n",
        "        if qid not in scores:\n",
        "            continue\n",
        "        if qid_to_has_ans[qid]:\n",
        "            diff = scores[qid]\n",
        "        else:\n",
        "            if preds[qid]:\n",
        "                diff = -1\n",
        "            else:\n",
        "                diff = 0\n",
        "        cur_score += diff\n",
        "        if cur_score > best_score:\n",
        "            best_score = cur_score\n",
        "            best_thresh = na_probs[qid]\n",
        "\n",
        "    has_ans_score, has_ans_cnt = 0, 0\n",
        "    for qid in qid_list:\n",
        "        if not qid_to_has_ans[qid]:\n",
        "            continue\n",
        "        has_ans_cnt += 1\n",
        "\n",
        "        if qid not in scores:\n",
        "            continue\n",
        "        has_ans_score += scores[qid]\n",
        "\n",
        "    return 100.0 * best_score / len(scores), best_thresh, 1.0 * has_ans_score / has_ans_cnt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReSeOpYsWk_V"
      },
      "source": [
        "def find_all_best_thresh_v2(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans):\n",
        "    best_exact, exact_thresh, has_ans_exact = find_best_thresh_v2(preds, exact_raw, na_probs, qid_to_has_ans)\n",
        "    best_f1, f1_thresh, has_ans_f1 = find_best_thresh_v2(preds, f1_raw, na_probs, qid_to_has_ans)\n",
        "    main_eval[\"best_exact\"] = best_exact\n",
        "    main_eval[\"best_exact_thresh\"] = exact_thresh\n",
        "    main_eval[\"best_f1\"] = best_f1\n",
        "    main_eval[\"best_f1_thresh\"] = f1_thresh\n",
        "    main_eval[\"has_ans_exact\"] = has_ans_exact\n",
        "    main_eval[\"has_ans_f1\"] = has_ans_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNjLZBoGWrVi"
      },
      "source": [
        "def find_best_thresh(preds, scores, na_probs, qid_to_has_ans):\n",
        "    num_no_ans = sum(1 for k in qid_to_has_ans if not qid_to_has_ans[k])\n",
        "    cur_score = num_no_ans\n",
        "    best_score = cur_score\n",
        "    best_thresh = 0.0\n",
        "    qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n",
        "    for _, qid in enumerate(qid_list):\n",
        "        if qid not in scores:\n",
        "            continue\n",
        "        if qid_to_has_ans[qid]:\n",
        "            diff = scores[qid]\n",
        "        else:\n",
        "            if preds[qid]:\n",
        "                diff = -1\n",
        "            else:\n",
        "                diff = 0\n",
        "        cur_score += diff\n",
        "        if cur_score > best_score:\n",
        "            best_score = cur_score\n",
        "            best_thresh = na_probs[qid]\n",
        "    return 100.0 * best_score / len(scores), best_thresh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjaAQmF0W933"
      },
      "source": [
        "def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans):\n",
        "    best_exact, exact_thresh = find_best_thresh(preds, exact_raw, na_probs, qid_to_has_ans)\n",
        "    best_f1, f1_thresh = find_best_thresh(preds, f1_raw, na_probs, qid_to_has_ans)\n",
        "\n",
        "    main_eval[\"best_exact\"] = best_exact\n",
        "    main_eval[\"best_exact_thresh\"] = exact_thresh\n",
        "    main_eval[\"best_f1\"] = best_f1\n",
        "    main_eval[\"best_f1_thresh\"] = f1_thresh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYld8b1KW9xF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHeQsrAdWCQ_"
      },
      "source": [
        "def squad_evaluate(examples, preds, no_answer_probs=None, no_answer_probability_threshold=1.0):\n",
        "    qas_id_to_has_answer = {example.qas_id: bool(example.answers) for example in examples}\n",
        "    has_answer_qids = [qas_id for qas_id, has_answer in qas_id_to_has_answer.items() if has_answer]\n",
        "    no_answer_qids = [qas_id for qas_id, has_answer in qas_id_to_has_answer.items() if not has_answer]\n",
        "\n",
        "    if no_answer_probs is None:\n",
        "        no_answer_probs = {k: 0.0 for k in preds}\n",
        "\n",
        "    exact, f1 = get_raw_scores(examples, preds)\n",
        "\n",
        "    exact_threshold = apply_no_ans_threshold(\n",
        "        exact, no_answer_probs, qas_id_to_has_answer, no_answer_probability_threshold\n",
        "    )\n",
        "    f1_threshold = apply_no_ans_threshold(f1, no_answer_probs, qas_id_to_has_answer, no_answer_probability_threshold)\n",
        "\n",
        "    evaluation = make_eval_dict(exact_threshold, f1_threshold)\n",
        "\n",
        "    if has_answer_qids:\n",
        "        has_ans_eval = make_eval_dict(exact_threshold, f1_threshold, qid_list=has_answer_qids)\n",
        "        merge_eval(evaluation, has_ans_eval, \"HasAns\")\n",
        "\n",
        "    if no_answer_qids:\n",
        "        no_ans_eval = make_eval_dict(exact_threshold, f1_threshold, qid_list=no_answer_qids)\n",
        "        merge_eval(evaluation, no_ans_eval, \"NoAns\")\n",
        "\n",
        "    if no_answer_probs:\n",
        "        find_all_best_thresh(evaluation, preds, exact, f1, no_answer_probs, qas_id_to_has_answer)\n",
        "\n",
        "    return evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS0omT24WCTx"
      },
      "source": [
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "\n",
        "def compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkUas_jgZIQr"
      },
      "source": [
        "tuples_fin_preds = []\n",
        "for l in processed_fin_preds:\n",
        "    id, ans = l\n",
        "    tuples_fin_preds.append((id, ans))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBfmrvaJa2-z"
      },
      "source": [
        "from collections import OrderedDict\n",
        "dict_l = OrderedDict(tuples_fin_preds)\n",
        "print(dict_l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwKLo5VwYpDR"
      },
      "source": [
        "fin_res = squad_evaluate(examples, dict_l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8gLW8U2abBI",
        "outputId": "41910429-c775-4d7c-9f18-65591c54f296"
      },
      "source": [
        "fin_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 80.71254105954687),\n",
              "             ('f1', 83.4004840855398),\n",
              "             ('total', 11873),\n",
              "             ('HasAns_exact', 73.4480431848853),\n",
              "             ('HasAns_f1', 78.83163757550851),\n",
              "             ('HasAns_total', 5928),\n",
              "             ('NoAns_exact', 87.95626576955425),\n",
              "             ('NoAns_f1', 87.95626576955425),\n",
              "             ('NoAns_total', 5945),\n",
              "             ('best_exact', 80.71254105954687),\n",
              "             ('best_exact_thresh', 0.0),\n",
              "             ('best_f1', 83.40048408553969),\n",
              "             ('best_f1_thresh', 0.0)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzib3vgObJD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}