{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bidaf_with_one_full_pass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVVsy3QwMc3h"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "In this notebook we perform one forward pass using BERT embeddings in BiDAF network. This is done for demonstration purposes. The forward pass is performed on a batch of 64 samples. \r\n",
        "\r\n",
        "To perform full training the code from this notebook is copied into the 'models' and 'layers' files of BiDAF implementation from Stanford. \r\n",
        "For details on the code that is concerned with BERT embedding replacement, refer the 'embedding_replacement' in this repository.\r\n",
        "\r\n",
        "The implementation of code might seem inefficient but this was done for easy merging with the BiDAF implementation from Stanford."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsfVBQLUqPnL"
      },
      "source": [
        "import torch \r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ7odhVoqPjO",
        "outputId": "ed76c2cf-f224-4c64-86df-a5d654e39792"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\r\n",
        "&& cd transformers \\\r\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWZkXsCqPeh",
        "outputId": "63c93c5e-512b-4ab4-b932-17c0710851ce"
      },
      "source": [
        "!pip install ./transformers\r\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.16.36)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.1.94)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.36 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.19.36)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.36->boto3->transformers==2.3.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp36-none-any.whl size=458556 sha256=890dc92db49dd4bf5a02f6977d8360f3d786066d01318fdb9c2b0c9b516df627\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jxbuvok4/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 2.3.0\n",
            "    Uninstalling transformers-2.3.0:\n",
            "      Successfully uninstalled transformers-2.3.0\n",
            "Successfully installed transformers-2.3.0\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIjFQAhPqPXZ"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\r\n",
        "from transformers import BertTokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch \r\n",
        "from transformers import BertModel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrLgMv33qVkF"
      },
      "source": [
        "import json  \r\n",
        "f = open('/content/word2idx.json',) \r\n",
        "data = json.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiCzYOBUqVcI"
      },
      "source": [
        "idx2word = {}\r\n",
        "for key in data.keys():\r\n",
        "    idx2word[data[key]] = key"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sw2UGi9qVXx"
      },
      "source": [
        "# Tensors obtained from the pre-processing steps of the base line BiDAF \r\n",
        "# These tensors will now be transformed into equivalent BERT embeddings.\r\n",
        "\r\n",
        "# Context file for one batch\r\n",
        "import pickle\r\n",
        "with open('cw_idxs.pickle', 'rb') as handle:\r\n",
        "    cw_idxs = pickle.load(handle)\r\n",
        "\r\n",
        "# Question file for one batch\r\n",
        "with open('qw_idxs.pickle', 'rb') as handle:\r\n",
        "    qw_idxs = pickle.load(handle)\r\n",
        "\r\n",
        "# Answer starts\r\n",
        "with open('y1.pickle', 'rb') as handle:\r\n",
        "    y1 = pickle.load(handle)\r\n",
        "\r\n",
        "# Answer ends\r\n",
        "with open('y2.pickle', 'rb') as handle:\r\n",
        "    y2 = pickle.load(handle)  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T60vz249qhXq",
        "outputId": "d10c5acb-e75e-4bd3-8708-396cae0ff0d3"
      },
      "source": [
        "# shapes of pre-processed tensors\r\n",
        "\r\n",
        "print(cw_idxs.shape)\r\n",
        "print(qw_idxs.shape)\r\n",
        "print(y1.shape)\r\n",
        "print(y2.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 376])\n",
            "torch.Size([64, 23])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rsHNOKfqhTO",
        "outputId": "9e18792e-564a-46a6-bc82-fc7cfc23297e"
      },
      "source": [
        "b = 64\r\n",
        "cw_idxs = cw_idxs[:b]\r\n",
        "qw_idxs = qw_idxs[:b]\r\n",
        "y1 = y1[:b]\r\n",
        "y2 = y2[:b]\r\n",
        "\r\n",
        "print(cw_idxs.shape)\r\n",
        "print(qw_idxs.shape)\r\n",
        "print(y1.shape)\r\n",
        "print(y2.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 376])\n",
            "torch.Size([64, 23])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HD6yawgqhPc"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rMSKJeXqhLZ"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjNqMFBlpAsY"
      },
      "source": [
        "# NEW SWAP_TOKENS FUNCTION\r\n",
        "def swap_tokens(cw_idxs):\r\n",
        "    cw_idxs_words = []\r\n",
        "    for c in cw_idxs:\r\n",
        "        new_list = []\r\n",
        "        for i in c:\r\n",
        "            new_list.append(idx2word[i.item()])\r\n",
        "        cw_idxs_words.append(new_list) \r\n",
        "\r\n",
        "    sentences = []\r\n",
        "    for l in cw_idxs_words:\r\n",
        "        sent = []\r\n",
        "        for i in l:\r\n",
        "            if i=='--OOV--' or i =='--NULL--':\r\n",
        "                continue\r\n",
        "            else:\r\n",
        "                sent.append(i)\r\n",
        "\r\n",
        "        sent = ' '.join(sent)   \r\n",
        "        sentences.append(sent)\r\n",
        "\r\n",
        "    sentences_tokenized = []\r\n",
        "\r\n",
        "    bert_words = []\r\n",
        "    for s in sentences:\r\n",
        "        tt = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(s))\r\n",
        "        bert_words.append(tokenizer.convert_ids_to_tokens(tt))\r\n",
        "        tt = torch.Tensor(tt).type(torch.LongTensor)\r\n",
        "        sentences_tokenized.append(tt)\r\n",
        "\r\n",
        "    max_len = 0\r\n",
        "    for s in sentences_tokenized:\r\n",
        "        max_len = max(len(s),max_len)\r\n",
        "\r\n",
        "    sentences_tokenized_tensors = [] \r\n",
        "    for s in sentences_tokenized:\r\n",
        "        tt = torch.nn.ConstantPad1d((0, max_len - s.shape[0]), 0)(s)\r\n",
        "        sentences_tokenized_tensors.append(tt)\r\n",
        "\r\n",
        "    CT_new = torch.Tensor([])\r\n",
        "\r\n",
        "    for l in sentences_tokenized_tensors:\r\n",
        "        l = l.reshape((1,l.shape[0]))\r\n",
        "        CT_new = torch.cat((CT_new, l), 0)   \r\n",
        "\r\n",
        "    c_mask = torch.zeros_like(CT_new) != CT_new \r\n",
        "\r\n",
        "    return (CT_new, c_mask, bert_words)    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDHcm_tipAn1"
      },
      "source": [
        "def collect_hash_words(bert_words):\r\n",
        "    import more_itertools as mit\r\n",
        "    hash_words_list = []\r\n",
        "\r\n",
        "    for sample in range(len(bert_words)):\r\n",
        "        test_mask = []\r\n",
        "        for i in range(len(bert_words[sample])):\r\n",
        "            if '#' in bert_words[sample][i]:\r\n",
        "                test_mask.append(1)\r\n",
        "            else:\r\n",
        "                test_mask.append(0)\r\n",
        "\r\n",
        "        ones = []\r\n",
        "        for i in range(len(test_mask)):\r\n",
        "            if test_mask[i]==1:\r\n",
        "                ones.append(i)\r\n",
        "\r\n",
        "        start_ones = []\r\n",
        "        for i in ones:\r\n",
        "            start_ones.append(i-1)\r\n",
        "        full_ones = sorted(list(set(sorted(start_ones + ones))))\r\n",
        "\r\n",
        "        ll = [list(group) for group in mit.consecutive_groups(full_ones)] \r\n",
        "        hash_words_list.append(ll)\r\n",
        "\r\n",
        "    return hash_words_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH-FTXbvpAYK"
      },
      "source": [
        "# model_name_or_path = 'bert-base-uncased'\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from transformers import BertModel\r\n",
        "from tqdm import tqdm\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "hidden_size = 100\r\n",
        "\r\n",
        "class Bertify(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, hidden_size):\r\n",
        "    super(Bertify, self).__init__()\r\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "  \r\n",
        "  def forward(self, input_ids, attention_mask):\r\n",
        "    last_hidden_state ,_ = self.bert(input_ids=input_ids,attention_mask=attention_mask)\r\n",
        "    output = last_hidden_state\r\n",
        "    return output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBGpjspLpAVr"
      },
      "source": [
        "def remove_hash(f, hash_words_list, hs):\r\n",
        "    sub = []\r\n",
        "    for l in hash_words_list[f]:\r\n",
        "        arr = []\r\n",
        "        for i in l:\r\n",
        "            c = hs[f][i].detach().numpy()\r\n",
        "            arr.append(c)\r\n",
        "\r\n",
        "        arr = np.array(arr)\r\n",
        "        arr = np.mean(arr, axis=0)\r\n",
        "        sub.append((arr, l[0]))\r\n",
        "\r\n",
        "    # sub --> [([],__),  ([],__),  ([],__)....]    \r\n",
        "\r\n",
        "    #  Replace all means\r\n",
        "    for s,i in sub:\r\n",
        "        hs[f][i] = torch.Tensor(s)     \r\n",
        "\r\n",
        "    # Remove unnecessary values\r\n",
        "    remove = []\r\n",
        "    for l in hash_words_list[f]:\r\n",
        "        remove.append(l[1:])\r\n",
        "    flat_list = [item for sublist in remove for item in sublist]  \r\n",
        "\r\n",
        "\r\n",
        "    hs_new = torch.Tensor([])\r\n",
        "    for i in range(len(hs[f])):\r\n",
        "        if i in flat_list:\r\n",
        "            continue\r\n",
        "        else:    \r\n",
        "            p = hs[f][i].reshape((1,-1))\r\n",
        "            hs_new = torch.cat((hs_new, p), 0)\r\n",
        "\r\n",
        "    return hs_new, flat_list        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HJwNEFRpATo"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP93lZ93pAPO"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgmb219AlwK0"
      },
      "source": [
        "def generate_final_bert_embeddings(cw_idxs, q_or_c):\r\n",
        "    context, context_m, bert_words_C = swap_tokens(cw_idxs)\r\n",
        "    hash_words_list_C = collect_hash_words(bert_words_C)\r\n",
        "\r\n",
        "    context = torch.Tensor(context).type(torch.LongTensor)\r\n",
        "\r\n",
        "    model = Bertify(hidden_size)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        c_hs = model(input_ids=context[:b].reshape((b,context.shape[1])), \r\n",
        "                attention_mask=context_m[:b].reshape((b,context.shape[1])))\r\n",
        "    \r\n",
        "    all_mods = []\r\n",
        "    all_falt_lists_C = []\r\n",
        "\r\n",
        "    for i in range(b):\r\n",
        "        hs_new, flat_list = remove_hash(i, hash_words_list_C, c_hs)\r\n",
        "        all_falt_lists_C.append(flat_list)\r\n",
        "        all_mods.append(hs_new)\r\n",
        "\r\n",
        "    if q_or_c == 'c':\r\n",
        "        max_len = 388\r\n",
        "    elif q_or_c == 'q':\r\n",
        "        max_len = 25\r\n",
        "\r\n",
        "    all_mods_tensors = [] \r\n",
        "    for s in all_mods:\r\n",
        "        tt = torch.transpose(torch.nn.ConstantPad2d((0, max_len - s.shape[0]), 0)(torch.transpose(s, 0, 1)), 0, 1)\r\n",
        "        all_mods_tensors.append(tt) \r\n",
        "\r\n",
        "    rect_c_hs = torch.Tensor([])\r\n",
        "    for l in all_mods_tensors:\r\n",
        "        l = l.reshape((1,l.shape[0], l.shape[1]))\r\n",
        "        rect_c_hs = torch.cat((rect_c_hs, l), 0) \r\n",
        "\r\n",
        "    print(rect_c_hs.shape)    \r\n",
        "\r\n",
        "    # generating new mask\r\n",
        "    context_np = context.numpy()       \r\n",
        "\r\n",
        "    all_mod_mask_C = []\r\n",
        "    for i in range(len(context_np)):\r\n",
        "        arr = []\r\n",
        "        for j in range(len(context_np[i])):\r\n",
        "            if j in all_falt_lists_C[i]:\r\n",
        "                continue\r\n",
        "            else:\r\n",
        "                arr.append(context_np[i][j])\r\n",
        "\r\n",
        "        for z in range(len(all_falt_lists_C[i])):\r\n",
        "            arr.append(0)\r\n",
        "        all_mod_mask_C.append(arr) \r\n",
        "\r\n",
        "    all_mod_mask_C_pt = []\r\n",
        "\r\n",
        "    for l in all_mod_mask_C:\r\n",
        "        all_mod_mask_C_pt.append(torch.Tensor(l))     \r\n",
        "\r\n",
        "    context_new = torch.Tensor([])\r\n",
        "\r\n",
        "    for l in all_mod_mask_C_pt:\r\n",
        "        l = l.reshape((1,l.shape[0]))\r\n",
        "        context_new = torch.cat((context_new, l), 0)\r\n",
        "\r\n",
        "    c_mask = torch.zeros_like(context_new) != context_new     \r\n",
        "\r\n",
        "    print(c_mask.shape)    \r\n",
        "\r\n",
        "    c_len = c_mask.sum(-1)\r\n",
        "    print(c_len.shape)  \r\n",
        "         \r\n",
        "    return rect_c_hs, c_mask, c_len\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3nBFwAUlwHE",
        "outputId": "ba024183-0a42-4515-d9e6-8b4a42e4100c"
      },
      "source": [
        "c_emb_new, c_mask, c_len = generate_final_bert_embeddings(cw_idxs, 'c')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 388, 768])\n",
            "torch.Size([64, 388])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnMXppZWq77R",
        "outputId": "7cad42f9-359f-427d-d3d6-575c4656dba1"
      },
      "source": [
        "q_emb_new, q_mask, q_len = generate_final_bert_embeddings(qw_idxs, 'q')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 25, 768])\n",
            "torch.Size([64, 25])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtAlsDBg71Jr"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaY6DWF4PMci"
      },
      "source": [
        "Implementing the layers of BiDAF network. For more details on the formulation of the layers, refer the project handout in this repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eP8uyaYsSwa"
      },
      "source": [
        "class HighwayEncoder(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, num_layers, hidden_size):\r\n",
        "        super(HighwayEncoder, self).__init__()\r\n",
        "        self.transforms = nn.ModuleList([nn.Linear(hidden_size, hidden_size)\r\n",
        "                                         for _ in range(num_layers)])\r\n",
        "        self.gates = nn.ModuleList([nn.Linear(hidden_size, hidden_size)\r\n",
        "                                    for _ in range(num_layers)])\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        for gate, transform in zip(self.gates, self.transforms):\r\n",
        "            # Shapes of g, t, and x are all (batch_size, seq_len, hidden_size)\r\n",
        "            g = torch.sigmoid(gate(x))\r\n",
        "            t = F.relu(transform(x))\r\n",
        "            x = g * t + (1 - g) * x\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "# model_name_or_path = 'bert-base-uncased'\r\n",
        "hidden_size = 100\r\n",
        "class Bert_Embeddings(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, hidden_size):\r\n",
        "    super(Bert_Embeddings, self).__init__()\r\n",
        "    # self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\r\n",
        "    self.drop = nn.Dropout(p=0.1)\r\n",
        "    self.lin = nn.Linear(768, hidden_size)\r\n",
        "    self.hwy = HighwayEncoder(2, hidden_size)\r\n",
        "  \r\n",
        "  def forward(self, c_emb):\r\n",
        "    # last_hidden_state ,_ = self.bert(input_ids=input_ids,attention_mask=attention_mask)\r\n",
        "    output = self.drop(c_emb)\r\n",
        "    # output = last_hidden_state\r\n",
        "    output = self.lin(output)\r\n",
        "    output = self.hwy(output)\r\n",
        "    return output        "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioY3O1k3yd9Z"
      },
      "source": [
        "class RNNEncoder(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self,\r\n",
        "                 input_size,\r\n",
        "                 hidden_size,\r\n",
        "                 num_layers,\r\n",
        "                 drop_prob=0.):\r\n",
        "        super(RNNEncoder, self).__init__()\r\n",
        "        self.drop_prob = drop_prob\r\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers,\r\n",
        "                           batch_first=True,\r\n",
        "                           bidirectional=True,\r\n",
        "                           dropout=drop_prob if num_layers > 1 else 0.)\r\n",
        "\r\n",
        "    def forward(self, x, lengths):\r\n",
        "        # Save original padded length for use by pad_packed_sequence\r\n",
        "        orig_len = x.size(1)\r\n",
        "\r\n",
        "        # Sort by length and pack sequence for RNN\r\n",
        "        lengths, sort_idx = lengths.sort(0, descending=True)\r\n",
        "        x = x[sort_idx]     # (batch_size, seq_len, input_size)\r\n",
        "        x = pack_padded_sequence(x, lengths, batch_first=True)\r\n",
        "\r\n",
        "        # Apply RNN\r\n",
        "        x, _ = self.rnn(x)  # (batch_size, seq_len, 2 * hidden_size)\r\n",
        "\r\n",
        "        # Unpack and reverse sort\r\n",
        "        x, _ = pad_packed_sequence(x, batch_first=True, total_length=orig_len)\r\n",
        "        _, unsort_idx = sort_idx.sort(0)\r\n",
        "        x = x[unsort_idx]   # (batch_size, seq_len, 2 * hidden_size)\r\n",
        "\r\n",
        "        # Apply dropout (RNN applies dropout after all but the last layer)\r\n",
        "        x = F.dropout(x, self.drop_prob, self.training)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaCvp-6nygFv"
      },
      "source": [
        "class BiDAFAttention(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, hidden_size, drop_prob=0.1):\r\n",
        "        super(BiDAFAttention, self).__init__()\r\n",
        "        self.drop_prob = drop_prob\r\n",
        "        self.c_weight = nn.Parameter(torch.zeros(hidden_size, 1))\r\n",
        "        self.q_weight = nn.Parameter(torch.zeros(hidden_size, 1))\r\n",
        "        self.cq_weight = nn.Parameter(torch.zeros(1, 1, hidden_size))\r\n",
        "        for weight in (self.c_weight, self.q_weight, self.cq_weight):\r\n",
        "            nn.init.xavier_uniform_(weight)\r\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\r\n",
        "\r\n",
        "    def forward(self, c, q, c_mask, q_mask):\r\n",
        "        batch_size, c_len, _ = c.size()\r\n",
        "        q_len = q.size(1)\r\n",
        "        s = self.get_similarity_matrix(c, q)        # (batch_size, c_len, q_len)\r\n",
        "        c_mask = c_mask.view(batch_size, c_len, 1)  # (batch_size, c_len, 1)\r\n",
        "        q_mask = q_mask.view(batch_size, 1, q_len)  # (batch_size, 1, q_len)\r\n",
        "        s1 = masked_softmax(s, q_mask, dim=2)       # (batch_size, c_len, q_len)\r\n",
        "        s2 = masked_softmax(s, c_mask, dim=1)       # (batch_size, c_len, q_len)\r\n",
        "\r\n",
        "        # (bs, c_len, q_len) x (bs, q_len, hid_size) => (bs, c_len, hid_size)\r\n",
        "        a = torch.bmm(s1, q)\r\n",
        "        # (bs, c_len, c_len) x (bs, c_len, hid_size) => (bs, c_len, hid_size)\r\n",
        "        b = torch.bmm(torch.bmm(s1, s2.transpose(1, 2)), c)\r\n",
        "\r\n",
        "        x = torch.cat([c, a, c * a, c * b], dim=2)  # (bs, c_len, 4 * hid_size)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def get_similarity_matrix(self, c, q):\r\n",
        "\r\n",
        "        c_len, q_len = c.size(1), q.size(1)\r\n",
        "        c = F.dropout(c, self.drop_prob, self.training)  # (bs, c_len, hid_size)\r\n",
        "        q = F.dropout(q, self.drop_prob, self.training)  # (bs, q_len, hid_size)\r\n",
        "\r\n",
        "        # Shapes: (batch_size, c_len, q_len)\r\n",
        "        s0 = torch.matmul(c, self.c_weight).expand([-1, -1, q_len])\r\n",
        "        s1 = torch.matmul(q, self.q_weight).transpose(1, 2)\\\r\n",
        "                                           .expand([-1, c_len, -1])\r\n",
        "        s2 = torch.matmul(c * self.cq_weight, q.transpose(1, 2))\r\n",
        "        s = s0 + s1 + s2 + self.bias\r\n",
        "\r\n",
        "        return s"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kS_YfHayh_K"
      },
      "source": [
        "class BiDAFOutput(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, hidden_size, drop_prob):\r\n",
        "        super(BiDAFOutput, self).__init__()\r\n",
        "        self.att_linear_1 = nn.Linear(8 * hidden_size, 1)\r\n",
        "        self.mod_linear_1 = nn.Linear(2 * hidden_size, 1)\r\n",
        "\r\n",
        "        self.rnn = RNNEncoder(input_size=2 * hidden_size,\r\n",
        "                              hidden_size=hidden_size,\r\n",
        "                              num_layers=1,\r\n",
        "                              drop_prob=drop_prob)\r\n",
        "\r\n",
        "        self.att_linear_2 = nn.Linear(8 * hidden_size, 1)\r\n",
        "        self.mod_linear_2 = nn.Linear(2 * hidden_size, 1)\r\n",
        "\r\n",
        "    def forward(self, att, mod, mask):\r\n",
        "        # Shapes: (batch_size, seq_len, 1)\r\n",
        "        logits_1 = self.att_linear_1(att) + self.mod_linear_1(mod)\r\n",
        "        mod_2 = self.rnn(mod, mask.sum(-1))\r\n",
        "        logits_2 = self.att_linear_2(att) + self.mod_linear_2(mod_2)\r\n",
        "\r\n",
        "        # Shapes: (batch_size, seq_len)\r\n",
        "        log_p1 = masked_softmax(logits_1.squeeze(), mask, log_softmax=True)\r\n",
        "        log_p2 = masked_softmax(logits_2.squeeze(), mask, log_softmax=True)\r\n",
        "\r\n",
        "        return log_p1, log_p2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_wAIjwykZm"
      },
      "source": [
        "def masked_softmax(logits, mask, dim=-1, log_softmax=False):\r\n",
        "    \r\n",
        "    mask = mask.type(torch.float32)\r\n",
        "    masked_logits = mask * logits + (1 - mask) * -1e30\r\n",
        "    softmax_fn = F.log_softmax if log_softmax else F.softmax\r\n",
        "    probs = softmax_fn(masked_logits, dim)\r\n",
        "\r\n",
        "    return probs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb85kbG-sS4G"
      },
      "source": [
        "hidden_size = 100\r\n",
        "\r\n",
        "class BiDAF(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, hidden_size, drop_prob=0.):\r\n",
        "        super(BiDAF, self).__init__()\r\n",
        "        self.bert_emb = Bert_Embeddings(hidden_size=hidden_size)\r\n",
        "\r\n",
        "        self.enc = RNNEncoder(input_size=hidden_size,\r\n",
        "                                     hidden_size=hidden_size,\r\n",
        "                                     num_layers=1,\r\n",
        "                                     drop_prob=drop_prob)\r\n",
        "\r\n",
        "        self.att = BiDAFAttention(hidden_size=2 * hidden_size,\r\n",
        "                                         drop_prob=drop_prob)\r\n",
        "\r\n",
        "        self.mod = RNNEncoder(input_size=8 * hidden_size,\r\n",
        "                                     hidden_size=hidden_size,\r\n",
        "                                     num_layers=2,\r\n",
        "                                     drop_prob=drop_prob)\r\n",
        "\r\n",
        "        self.out = BiDAFOutput(hidden_size=hidden_size,\r\n",
        "                                      drop_prob=drop_prob)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, cw_idxs, qw_idxs):\r\n",
        "        \r\n",
        "        c_emb_new, c_mask, c_len = generate_final_bert_embeddings(cw_idxs, 'c')\r\n",
        "        q_emb_new, q_mask, q_len = generate_final_bert_embeddings(qw_idxs, 'q')\r\n",
        "\r\n",
        "        c_emb_new = c_emb_new.to(device)\r\n",
        "        q_emb_new = q_emb_new.to(device)\r\n",
        "        c_mask = c_mask.to(device)\r\n",
        "        q_mask = q_mask.to(device)\r\n",
        "        \r\n",
        "        c_emb = self.bert_emb(c_emb_new)\r\n",
        "        q_emb = self.bert_emb(q_emb_new)\r\n",
        "        \r\n",
        "        print(\"------------\")\r\n",
        "        print(c_emb.shape)\r\n",
        "        print(q_emb.shape)\r\n",
        "\r\n",
        "        c_enc = self.enc(c_emb, c_len)   \r\n",
        "        q_enc = self.enc(q_emb, q_len) \r\n",
        "\r\n",
        "        print(\"------------\")\r\n",
        "        print(c_enc.shape)\r\n",
        "        print(q_enc.shape) \r\n",
        "\r\n",
        "        att = self.att(c_enc, q_enc,\r\n",
        "                       c_mask, q_mask) \r\n",
        "        \r\n",
        "        print(\"------------\")\r\n",
        "        print(att.shape)\r\n",
        "\r\n",
        "        mod = self.mod(att, c_len)  \r\n",
        "\r\n",
        "        print(\"------------\")\r\n",
        "        print(mod.shape)\r\n",
        "\r\n",
        "        out = self.out(att, mod, c_mask)\r\n",
        "        print(\"------------\")\r\n",
        "        # print(out.shape)\r\n",
        "\r\n",
        "        return out"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKjLQiBEscVa",
        "outputId": "d7c061f9-c846-4462-ecc7-2a01cf3f7d5e"
      },
      "source": [
        "hidden_size = 100\r\n",
        "bidaf_model = BiDAF(hidden_size = hidden_size)\r\n",
        "bidaf_model = bidaf_model.to(device)\r\n",
        "log_p1, log_p2 = bidaf_model(cw_idxs, qw_idxs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 388, 768])\n",
            "torch.Size([64, 388])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 25, 768])\n",
            "torch.Size([64, 25])\n",
            "torch.Size([64])\n",
            "------------\n",
            "torch.Size([64, 388, 100])\n",
            "torch.Size([64, 25, 100])\n",
            "------------\n",
            "torch.Size([64, 388, 200])\n",
            "torch.Size([64, 25, 200])\n",
            "------------\n",
            "torch.Size([64, 388, 800])\n",
            "------------\n",
            "torch.Size([64, 388, 200])\n",
            "------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jf2Ir46sb-p"
      },
      "source": [
        "loss = F.nll_loss(log_p1, y1[:b]) + F.nll_loss(log_p2, y2[:b])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pk3yXJ9Pkgg"
      },
      "source": [
        "Loss after one full pass through the BiDAF network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EezGjUxYyvTk",
        "outputId": "fa2d60e8-d99c-499c-9884-3a9c508c78b6"
      },
      "source": [
        "loss"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.9463, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xyN2Z-yvMD"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8lUtXjryvHd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}